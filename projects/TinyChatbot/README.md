# ğŸ¤– TinyChatBot â€” Modular RAG Chatbot Framework

**TinyChatBot** is a lightweight, modular project that demonstrates how to build a **Retrieval-Augmented Generation (RAG)**â€“based chatbot using modern open-source tools.  
It is designed for self-learning, experimentation, and fast prototyping with multiple model backends.

> â€œFlexible. Portable. Understandable.â€ â€” TinyChatBot helps you learn how modern AI chat systems are built.

---

## ğŸ§  Core Idea

The goal of **TinyChatBot** is to explore **how RAG pipelines work**:
1. ğŸ§© *Retrieve* relevant context from your local knowledge base  
2. ğŸ’¬ *Augment* user queries with the retrieved context  
3. ğŸ§  *Generate* a contextualized answer via your chosen LLM backend  

---

## âš™ï¸ Tech Stack

| Layer | Technology | Description |
|-------|-------------|-------------|
| ğŸ§  **Backend** | **Python**, **FastAPI** | RESTful API layer for query handling, retrieval, and response generation |
| ğŸ’¬ **Models** | **Ollama**, **LM Studio**, or **OpenAI GPT** | Switch between model providers easily |
| ğŸ” **Retrieval** | RAG pipeline with embeddings & vector database | Provides contextual grounding for chatbot answers |
| ğŸ³ **Deployment** | **Docker**, **docker-compose** | Simple and reproducible deployment across environments |
| ğŸ§© **Architecture** | Modular design (backend + frontend) | Easy to extend and customize |

---

## ğŸ§­ Project Structure

```
TinyChatBot/
â”œâ”€â”€ tinyrag-backend/       # FastAPI backend service (RAG logic, model integration)
â”œâ”€â”€ tinyrag-frontend/      # Frontend UI (React/Vite chat interface)
â”œâ”€â”€ docker-compose.yml     # Orchestrates backend + frontend services
â””â”€â”€ README.md              # This file
```

---

## ğŸš€ Quick Start

### ğŸ³ Option 1 â€” Run with Docker (recommended)

Make sure you have **Docker** and **docker-compose** installed.

```bash
docker-compose up --build
```

Then open:
- Frontend â†’ http://localhost:3000  
- Backend API â†’ http://localhost:8000/docs

---

### ğŸ Option 2 â€” Run manually (for development)

#### Backend
```bash
cd tinyrag-backend
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload
```
API available at http://localhost:8000/docs

#### Frontend
```bash
cd tinyrag-frontend
npm install
npm run dev
```
Frontend available at http://localhost:3000

---

## ğŸ§© Features

| Feature | Description |
|----------|--------------|
| **RAG Architecture** | Retrieve â†’ Augment â†’ Generate pipeline |
| **Pluggable Models** | Easily switch between Ollama, LM Studio, or GPT-based APIs |
| **FastAPI Backend** | Async API endpoints for chat and retrieval |
| **Dockerized Setup** | 1-command environment replication |
| **Custom Data Sources** | Extend retrieval logic to local files, docs, or databases |
| **Frontend Chat UI** | Simple web interface for chatting and visualizing context |

---

## ğŸ”§ Configuration

| File | Purpose |
|------|----------|
| `.env` | Define API keys, model settings, and backend ports |
| `docker-compose.yml` | Container orchestration |
| `requirements.txt` | Python dependencies |
| `vite.config.js` | Frontend build configuration |

Example `.env`:
```
MODEL_BACKEND=ollama
MODEL_NAME=llama3
VECTOR_DB_PATH=./data/vectorstore
OPENAI_API_KEY=your-key-here
```

---

## ğŸ§  Learning Focus

This project is ideal for:
- Practicing **FastAPI** + **LLM integration**
- Understanding **RAG (retrieval-augmented generation)** concepts
- Experimenting with **embeddings, vector stores**, and **contextual prompts**
- Learning how to **containerize AI microservices**

---

## ğŸ§° Tech Summary

| Category | Tool |
|-----------|------|
| Language | Python 3.10+ |
| API Framework | FastAPI |
| LLM Integration | Ollama / LM Studio / OpenAI |
| Vector Store | FAISS / Chroma (optional) |
| Containerization | Docker / docker-compose |
| Frontend | React + Vite |
| Platform | Cross-platform (macOS / Linux / Windows) |

---

## ğŸ§­ Future Enhancements
- Add **vector database persistence** (Chroma / FAISS / PostgreSQL)  
- Support for **RAG streaming responses**  
- Add **multi-model orchestration layer**  
- Integrate **embedding pipeline for PDF / text ingestion**

---

## ğŸ“œ License

MIT License â€” for learning, research, and experimentation.

---

**Author:** *Pham Minh Tuan*  
Â© 2025 â€” *TinyChatBot: Build, Learn, Share.*
